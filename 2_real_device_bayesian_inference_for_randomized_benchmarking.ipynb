{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference for Randomized Benchmarking\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook gives an example of how to use Bayesian inference as a help for randomized benchmarking. The Pymc3 and Arviz python packages are used for this purpose. Priors are obtained from the fitter included in the Qiskit ``ignis.verification.randomized_benchmarking``module. A pooled and a hierarchical model are tested and compared. The model's parameters are ajusted and the error per Clifford (EPC) is estimated, together with a credible interval. For reference, an EPC value is calculated from the noisy model of the simulation.\n",
    "\n",
    "Thes notebook is based on the examples of the ignis noise tutorial on randomized benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import general libraries (needed for functions)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "#Import Qiskit classes\n",
    "import qiskit\n",
    "from qiskit.providers.aer.noise import NoiseModel\n",
    "from qiskit.providers.aer.noise.errors.standard_errors import depolarizing_error, thermal_relaxation_error\n",
    "\n",
    "#Import the RB Functions\n",
    "import qiskit.ignis.verification.randomized_benchmarking as rb\n",
    "\n",
    "import copy\n",
    "\n",
    "# import the bayesian packages\n",
    "import pymc3 as pm\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "real"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shesha/anaconda3/envs/Qiskitenv/lib/python3.8/site-packages/qiskit/providers/ibmq/ibmqfactory.py:192: UserWarning: Timestamps in IBMQ backend properties, jobs, and job results are all now in local time instead of UTC.\n",
      "  warnings.warn('Timestamps in IBMQ backend properties, jobs, and job results '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<IBMQSimulator('ibmq_qasm_simulator') from IBMQ(hub='ibm-q', group='open', project='main')>,\n",
       " <IBMQBackend('ibmqx2') from IBMQ(hub='ibm-q', group='open', project='main')>,\n",
       " <IBMQBackend('ibmq_16_melbourne') from IBMQ(hub='ibm-q', group='open', project='main')>,\n",
       " <IBMQBackend('ibmq_armonk') from IBMQ(hub='ibm-q', group='open', project='main')>,\n",
       " <IBMQBackend('ibmq_athens') from IBMQ(hub='ibm-q', group='open', project='main')>,\n",
       " <IBMQBackend('ibmq_santiago') from IBMQ(hub='ibm-q', group='open', project='main')>,\n",
       " <IBMQBackend('ibmq_lima') from IBMQ(hub='ibm-q', group='open', project='main')>,\n",
       " <IBMQBackend('ibmq_belem') from IBMQ(hub='ibm-q', group='open', project='main')>,\n",
       " <IBMQBackend('ibmq_quito') from IBMQ(hub='ibm-q', group='open', project='main')>,\n",
       " <IBMQSimulator('simulator_statevector') from IBMQ(hub='ibm-q', group='open', project='main')>,\n",
       " <IBMQSimulator('simulator_mps') from IBMQ(hub='ibm-q', group='open', project='main')>,\n",
       " <IBMQSimulator('simulator_extended_stabilizer') from IBMQ(hub='ibm-q', group='open', project='main')>,\n",
       " <IBMQSimulator('simulator_stabilizer') from IBMQ(hub='ibm-q', group='open', project='main')>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qiskit import IBMQ\n",
    "IBMQ.load_account()\n",
    "provider = IBMQ.get_provider(hub='ibm-q')\n",
    "provider.backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.tools.monitor import job_monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "real"
    ]
   },
   "outputs": [],
   "source": [
    "device = provider.get_backend('ibmq_lima')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Bayesian extension\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Initialize random number generator\n",
    "RANDOM_SEED = 8927\n",
    "np.random.seed(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_priors_and_data_from_fitter(printout = True):\n",
    "    m_gates = copy.deepcopy(nCliffs)\n",
    "    # We choose the count matrix corresponding to 2 Qubit RB\n",
    "    Y = (np.array(rbfit._raw_data[0])*shots).astype(int)\n",
    "    \n",
    "    # alpha prior and bounds \n",
    "    alpha_ref = rbfit._fit[0]['params'][1]    \n",
    "    alpha_lower = alpha_ref - 2*rbfit._fit[0]['params_err'][1] # modified for real\n",
    "    alpha_upper = alpha_ref + 2*rbfit._fit[0]['params_err'][1] # modified for real\n",
    "    \n",
    "    # priors for A anbd B\n",
    "    mu_AB = np.delete(rbfit._fit[0]['params'],1)\n",
    "    cov_AB=np.delete(rbfit._fit[0]['params_err'],1)**2\n",
    "    \n",
    "    # prior for sigmatheta:\n",
    "    sigma_theta = 0.004    \n",
    "    if printout:\n",
    "        print(\"priors:\\nalpha_ref\",alpha_ref)\n",
    "        print(\"alpha_lower\", alpha_lower, \"alpha_upper\", alpha_upper)\n",
    "        print(\"A,B\", mu_AB, \"\\ncov A,B\", cov_AB)\n",
    "        print(\"sigma_theta\", sigma_theta)\n",
    "    \n",
    "    return m_gates, Y, alpha_ref, alpha_lower, alpha_upper, mu_AB, cov_AB, sigma_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bayesian_model(model_type):\n",
    "# Bayesian model\n",
    "# from https://iopscience.iop.org/article/10.1088/1367-2630/17/1/013042/pdf \n",
    "# see https://docs.pymc.io/api/model.html\n",
    "    \n",
    "    RB_model = pm.Model()\n",
    "    with RB_model:\n",
    "        #Priors for unknown model parameters\n",
    "        alpha = pm.Uniform(\"alpha\",lower=alpha_lower,\n",
    "                           upper=alpha_upper, testval = alpha_ref)\n",
    "        \n",
    "        BoundedMvNormal = pm.Bound(pm.MvNormal, lower=0.0)\n",
    "        \n",
    "        AB = BoundedMvNormal(\"AB\", mu=mu_AB,testval = mu_AB,\n",
    "                         cov= np.diag(cov_AB),\n",
    "                         shape = (2))\n",
    "\n",
    "        # Expected value of outcome\n",
    "        GSP = AB[0]*alpha**m_gates + AB[1]\n",
    "        \n",
    "        if model_type == \"pooled\":\n",
    "            total_shots = np.full(Y.shape, shots)\n",
    "            theta = GSP\n",
    "        \n",
    "        elif model_type == \"hierarchical\":\n",
    "            total_shots = np.full(Y.shape, shots)\n",
    "            theta = pm.Beta(\"GSP\",\n",
    "                         mu=GSP,\n",
    "                         sigma = sigma_theta,\n",
    "                         shape = Y.shape[1])\n",
    "        \n",
    "        # Likelihood (sampling distribution) of observations    \n",
    "        p = pm.Binomial(\"Counts\", p=theta, observed=Y,\n",
    "                            n = total_shots) \n",
    "\n",
    "    return RB_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace(RB_model):\n",
    "    # Gradient-based sampling methods\n",
    "    # see also: https://docs.pymc.io/notebooks/sampler-stats.html\n",
    "    # and https://docs.pymc.io/notebooks/api_quickstart.html\n",
    "    with RB_model:   \n",
    "        trace= pm.sample(draws = 2000, tune= 10000, target_accept=0.9, return_inferencedata=True)    \n",
    "\n",
    "    with RB_model:\n",
    "        az.plot_trace(trace);\n",
    "        \n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(RB_model, trace, hdi_prob=.94, kind='all'):\n",
    "    with RB_model:\n",
    "        #  (hdi_prob=.94 is default)\n",
    "        az_summary = az.summary(trace, round_to=4,  hdi_prob=hdi_prob, kind=kind )  \n",
    "        \n",
    "    return az_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain EPC from alpha (used by plot_posterior)\n",
    "def alpha_to_EPC(alpha):\n",
    "        return 3*(1-alpha)/4   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_EPC_and_legends(azs):\n",
    "    EPC_Bayes = alpha_to_EPC(azs['mean']['alpha'])\n",
    "    EPC_Bayes_err = EPC_Bayes - alpha_to_EPC(azs['mean']['alpha']+azs['sd']['alpha'])\n",
    "    Bayes_legend =\"EPC Bayes {0:.5f} ({1:.5f})\".format(EPC_Bayes, EPC_Bayes_err)\n",
    "    Fitter_legend =\"EPC Fitter {0:.5f} ({1:.5f})\".format(rbfit.fit[0]['epc']\\\n",
    "                                                        ,rbfit._fit[0]['epc_err'])\n",
    "    pred_epc_legend = \"EPC predicted {0:.5f}\".format(pred_epc)\n",
    "    return EPC_Bayes, EPC_Bayes_err, Bayes_legend,Fitter_legend, pred_epc_legend\n",
    "    \n",
    "def EPC_compare_fitter_to_bayes(RB_model, azs, trace):\n",
    "    EPC_Bayes, EPC_Bayes_err, Bayes_legend,Fitter_legend, pred_epc_legend = get_EPC_and_legends(azs)\n",
    "    with RB_model:\n",
    "        az.plot_posterior(trace,  var_names=['alpha'], round_to=4,\n",
    "                          transform = alpha_to_EPC, point_estimate=None)\n",
    "        plt.title(\"Error per Clifford\")\n",
    "        plt.axvline(x=alpha_to_EPC(alpha_ref),color='red')\n",
    "        #plt.axvline(x=pred_epc,color='green') # WIP\n",
    "        #plt.legend((Bayes_legend, \"Higher density interval\",Fitter_legend, pred_epc_legend), fontsize=10 )# WIP\n",
    "        plt.legend((Bayes_legend, \"Higher density interval\",Fitter_legend), fontsize=10 )\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GSP_compare_fitter_to_bayes(RB_model, azs):\n",
    "    EPC_Bayes, EPC_Bayes_err, Bayes_legend,Fitter_legend,_ = get_EPC_and_legends(azs)\n",
    "    # plot ground state population ~ Clifford length\n",
    "    fig, axes = plt.subplots(1, 1, sharex=True, figsize=(10, 6))\n",
    "\n",
    "    axes.set_ylabel(\"Ground State Population\")\n",
    "    axes.set_xlabel(\"Clifford Length\")\n",
    "    axes.plot(m_gates, np.mean(Y/shots,axis=0), 'r.')\n",
    "    axes.plot(m_gates,azs['mean']['AB[0]']*azs['mean']['alpha']**m_gates+azs['mean']['AB[1]'],'--')\n",
    "    #axes.plot(m_gates,azs['mean']['GSP'],'--') # WIP\n",
    "    #axes.errorbar(m_gates, azs['mean']['GSP'], azs['sd']['GSP'], linestyle='None', marker='^') # WIP\n",
    "    axes.plot(m_gates,mu_AB[0]*np.power(alpha_ref,m_gates)+mu_AB[1],':') \n",
    "    for i_seed in range(nseeds):\n",
    "        plt.scatter(m_gates-0.25, Y[i_seed,:]/shots, label = \"data\", marker=\"x\")\n",
    "    axes.legend([\"Mean Observed Frequencies\",\n",
    "                 \"Bayesian Model\\n\"+Bayes_legend,\n",
    "                 \"Fitter Model\\n\"+Fitter_legend],fontsize=12)\n",
    "    #axes.set_title('2 Qubit RB with T1/T2 Noise', fontsize=18) # WIP\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_EPC(error_source):\n",
    "\n",
    "    #Count the number of single and 2Q gates in the 2Q Cliffords\n",
    "    gates_per_cliff = rb.rb_utils.gates_per_clifford(transpile_list,xdata[0],basis_gates,rb_opts['rb_pattern'][0])\n",
    "    for basis_gate in basis_gates:\n",
    "        print(\"Number of %s gates per Clifford: %f \"%(basis_gate ,\n",
    "                                                      np.mean([gates_per_cliff[rb_pattern[0][0]][basis_gate],\n",
    "                                                               gates_per_cliff[rb_pattern[0][1]][basis_gate]])))\n",
    "    # Calculate the predicted epc\n",
    "    # from the known depolarizing errors on the simulation\n",
    "    if error_source == \"depolarization\":  \n",
    "        # Error per gate from noise model\n",
    "        epgs_1q = {'u1': 0, 'u2': p1Q/2, 'u3': 2*p1Q/2}\n",
    "        epg_2q = p2Q*3/4\n",
    "        pred_epc = rb.rb_utils.calculate_2q_epc(\n",
    "            gate_per_cliff=gates_per_cliff,\n",
    "            epg_2q=epg_2q,\n",
    "            qubit_pair=[0, 2],\n",
    "            list_epgs_1q=[epgs_1q, epgs_1q])\n",
    "\n",
    "    # using the predicted primitive gate errors from the coherence limit\n",
    "    if error_source == \"from_T1_T2\": \n",
    "        # Predicted primitive gate errors from the coherence limit\n",
    "        u2_error = rb.rb_utils.coherence_limit(1,[t1],[t2],gate1Q)\n",
    "        u3_error = rb.rb_utils.coherence_limit(1,[t1],[t2],2*gate1Q)\n",
    "        epg_2q = rb.rb_utils.coherence_limit(2,[t1,t1],[t2,t2],gate2Q)\n",
    "        epgs_1q = {'u1': 0, 'u2': u2_error, 'u3': u3_error}\n",
    "        pred_epc = rb.rb_utils.calculate_2q_epc(\n",
    "            gate_per_cliff=gates_per_cliff,\n",
    "            epg_2q=epg_2q,\n",
    "            qubit_pair=[0, 1],\n",
    "            list_epgs_1q=[epgs_1q, epgs_1q])\n",
    "    return pred_epc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_data(result_list):\n",
    "### another way to obtain the observed counts \n",
    "\n",
    "    Y_list = []\n",
    "    for rbseed, result in enumerate(result_list):\n",
    "        row_list = []\n",
    "        for c_index, c_value in enumerate(nCliffs):\n",
    "            if nQ == 2: \n",
    "                list_bitstring = ['00']\n",
    "            elif nQ == 3:\n",
    "                list_bitstring = ['000', '100'] # because q2 measured in c1\n",
    "            total_counts = 0\n",
    "            for bitstring in list_bitstring:\n",
    "                    total_counts += result.get_counts()[c_index][bitstring]\n",
    "            row_list.append(total_counts)\n",
    "        Y_list.append(row_list)    \n",
    "    return np.array(Y_list)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters of the RB Run <a name='select_params_RB'></a>\n",
    "\n",
    "\n",
    "- **nseeds:** The number of seeds. For each seed you will get a separate list of output circuits in rb_circs.\n",
    "- **length_vector:** The length vector of Clifford lengths. Must be in ascending order. RB sequences of increasing length grow on top of the previous sequences.\n",
    "- **rb_pattern:** A list of the form [[i,j],[k],...] which will make simultaneous RB sequences where Qi,Qj are a 2-qubit RB sequence and Qk is a 1-qubit sequence, etc. The number of qubits is the sum of the entries. For 'regular' RB the qubit_pattern is just [[0]],[[0,1]].\n",
    "- **length_multiplier:** If this is an array it scales each rb_sequence by the multiplier.\n",
    "- **seed_offset:** What to start the seeds at (e.g. if we want to add more seeds later).\n",
    "- **align_cliffs:**  If true adds a barrier across all qubits in rb_pattern after each set of cliffords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the RB sequences <a name='gen_RB_seq'></a>\n",
    "\n",
    "In order to generate the RB sequences **rb_circs**, which is a list of lists of quantum circuits, \n",
    "we run the function `rb.randomized_benchmarking_seq`.\n",
    "\n",
    "This function returns:\n",
    "\n",
    "- **rb_circs:** A list of lists of circuits for the rb sequences (separate list for each seed).\n",
    "- **xdata:** The Clifford lengths (with multiplier if applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:49:09.963476Z",
     "start_time": "2019-12-10T21:49:09.960218Z"
    }
   },
   "outputs": [],
   "source": [
    "#Number of qubits\n",
    "nQ = 2\n",
    "#There are 2 qubits: Q0,Q1.\n",
    "#Number of seeds (random sequences)\n",
    "nseeds = 10 # more data for the Rev. Mr. Bayes\n",
    "#Number of Cliffords in the sequence (start, stop, steps)\n",
    "nCliffs = np.arange(1,200,20)\n",
    "#2Q RB Q0,Q1\n",
    "rb_pattern = [[0,1]]\n",
    "length_multiplier = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_opts  = {}\n",
    "rb_opts ['length_vector'] = nCliffs\n",
    "rb_opts ['nseeds'] = nseeds\n",
    "rb_opts ['rb_pattern'] = rb_pattern\n",
    "rb_opts ['length_multiplier'] = length_multiplier\n",
    "rb_circs , xdata  = rb.randomized_benchmarking_seq(**rb_opts )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "real"
    ]
   },
   "outputs": [],
   "source": [
    "backend = device\n",
    "basis_gates = ['u1','u2','u3','cx'] # use U,CX for now\n",
    "shots = 1024\n",
    "result_list = []\n",
    "transpile_list = []\n",
    "import time\n",
    "for rb_seed,rb_circ_seed in enumerate(rb_circs):\n",
    "    print('Compiling seed %d'%rb_seed)\n",
    "    rb_circ_transpile = qiskit.transpile(rb_circ_seed,\n",
    "                                         optimization_level=0,\n",
    "                                         basis_gates=basis_gates)\n",
    "    print('Runing seed %d'%rb_seed)\n",
    "    job = qiskit.execute(rb_circ_transpile, \n",
    "                         shots=shots,\n",
    "                         backend=backend)\n",
    "    job_monitor(job)\n",
    "    result_list.append(job.result())\n",
    "    transpile_list.append(rb_circ_transpile)    \n",
    "    \n",
    "print(\"Finished Real Jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rb_circs[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the RB results and calculate the gate fidelity <a name='fit_RB'></a>\n",
    "\n",
    "### Get statistics about the survival probabilities\n",
    "\n",
    "The results in **result_list** should fit to an exponentially decaying function $A \\cdot \\alpha ^ m + B$, where $m$ is the Clifford length.\n",
    "\n",
    "From $\\alpha$ we can calculate the **Error per Clifford (EPC)**:\n",
    "$$ EPC = \\frac{2^n-1}{2^n} (1-\\alpha)$$\n",
    "(where $n=nQ$ is the number of qubits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:51:13.840201Z",
     "start_time": "2019-12-10T21:51:13.497713Z"
    },
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "#Create an RBFitter object \n",
    "rbfit = rb.RBFitter(result_list, xdata, rb_opts['rb_pattern'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bayesian inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_gates, Y, alpha_ref, alpha_lower, alpha_upper, mu_AB, cov_AB, sigma_theta =\\\n",
    "    obtain_priors_and_data_from_fitter(printout = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### a check of the count matrix\n",
    "np.sum((Y == (get_count_data(result_list)))*1) == Y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pooled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled = get_bayesian_model(\"pooled\")\n",
    "pm.model_to_graphviz(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_p = get_trace(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azp_summary = get_summary(pooled, trace_p)\n",
    "azp_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical = get_bayesian_model(\"hierarchical\")\n",
    "pm.model_to_graphviz(hierarchical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_h = get_trace(hierarchical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azh_summary = get_summary(hierarchical, trace_h)\n",
    "azh_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare models\n",
    "ref: https://docs.pymc.io/notebooks/model_comparison.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-one-out Cross-validation (LOO) comparison\n",
    "df_comp_loo = az.compare({\"hierarchical\": trace_h, \"pooled\": trace_p})\n",
    "df_comp_loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_compare(df_comp_loo, insample_dev=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict EPC from the noisy model\n",
    "#pred_epc = get_predicted_EPC(error_source = 'from_T1_T2') # this was for a noise model\n",
    "pred_epc = 0.0165 # will not appear on graphs for real device but at this point functions need value (WIP)\n",
    "print(\"Fake 2Q Error per Clifford: %e\"%pred_epc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPC_compare_fitter_to_bayes(pooled, azp_summary, trace_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPC_compare_fitter_to_bayes(hierarchical, azh_summary, trace_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSP_compare_fitter_to_bayes(pooled, azp_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSP_compare_fitter_to_bayes(hierarchical, azh_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:51:14.059488Z",
     "start_time": "2019-12-10T21:51:13.949841Z"
    }
   },
   "outputs": [],
   "source": [
    "import qiskit.tools.jupyter\n",
    "%qiskit_version_table\n",
    "%qiskit_copyright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
